{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "af96c8fc",
   "metadata": {},
   "source": [
    "# Assignment 2 - Convolutional Neural Network\n",
    "\n",
    "## Data processing\n",
    "First of all, the data sets needs to be processed before feeded into the model training process. Therefore, the provided `load_dataset()` function handles it. Going further with the `ImageFolder` created from `load_dataset`, one can prepare it as `ConcatDataset` type to create a concatenated dataset for K-fold Cross Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45f620f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datapoints for training is 136 and for test is 34\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms, datasets\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import ConcatDataset\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "def load_dataset(train_path=r\"WF-data/train\", test_path=r\"WF-data/test\"):\n",
    "\n",
    "    transform = transforms.Compose([transforms.Resize([105, 78]),\n",
    "                                    transforms.CenterCrop(size=[60, 30]),\n",
    "                                    transforms.ToTensor()])\n",
    "    # target_transform = {\"ng\": 0, \"ok\": 1}\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(train_path, transform=transform, target_transform=None)\n",
    "    test_dataset = datasets.ImageFolder(test_path, transform=transform, target_transform=None)\n",
    "\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "\n",
    "# Creating the data set\n",
    "train_dataset, test_dataset = load_dataset()\n",
    "print(f\"Datapoints for training is {len(train_dataset)} and for test is {len(test_dataset)}\")\n",
    "\n",
    "# Preparing the K-fold\n",
    "data_set = ConcatDataset([train_dataset, test_dataset]) # Concatenating it for the K-fold\n",
    "kfold = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1439c0be",
   "metadata": {},
   "source": [
    "To display a sample of the data set, one can use the `ImageFolder` or even the `ConcatDataset` and permute it to get the RGB colour-spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fe67c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 29.5, 59.5, -0.5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy import random\n",
    "\n",
    "random_image = random.choice(len(data_set))\n",
    "\n",
    "img, labels = data_set[random_image][0], data_set[random_image][1]\n",
    "plt.imshow(img.permute(1,2,0)) # Permutation is used to display the image in RGB instead of gray colormap\n",
    "plt.title(labels)\n",
    "plt.axis(False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "51b423c8",
   "metadata": {},
   "source": [
    "## The Model\n",
    "\n",
    "This Convolutional Neural Network is based on the VGG architecture, which is a good model architecture for detail recognition. To implement it, we can use the [CNN Calculator](https://thanos.charisoudis.gr/blog/a-simple-conv2d-dimensions-calculator-logger) to build the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "418d9855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "    \n",
    "class ConvNeuralNet(nn.Module):\n",
    "\t#  Determine what layers and their order in CNN object \n",
    "    def __init__(self, num_classes=2):\n",
    "        super(ConvNeuralNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "                                    nn.Conv2d(3, 32, kernel_size = 3, stride = 1, padding = 1),\n",
    "                                    nn.BatchNorm2d(32),\n",
    "                                    nn.ReLU())\n",
    "        self.layer2 = nn.Sequential(\n",
    "                                    nn.Conv2d(32, 64, kernel_size = 3, stride = 1, padding = 1),\n",
    "                                    nn.BatchNorm2d(64),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "                                    nn.Conv2d(64, 128, kernel_size = 3, stride = 1, padding = 1),\n",
    "                                    nn.BatchNorm2d(128),\n",
    "                                    nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "                                    nn.Conv2d(128, 128, kernel_size = 3, stride = 1, padding = 1),\n",
    "                                    nn.BatchNorm2d(128),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "\n",
    "        self.fc1 = nn.Sequential(nn.Dropout(0.5), nn.Linear(7*15*128, 1800), nn.ReLU())\n",
    "        self.fc2 = nn.Sequential(nn.Dropout(0.5), nn.Linear(1800, 112), nn.ReLU())\n",
    "        self.dense = nn.Linear(112, num_classes)\n",
    "    \n",
    "    # Progresses data across layers    \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return self.dense(out)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd5ce6ea",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "For the hyperparameters, we define the Cross Entropy loss function and Adam optimiser algorithm. Furthermore, one can tweak around the suitable learning rate in the optimiser. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "678258ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.backends import mps\n",
    "\n",
    "\n",
    "# Creating the Early Stopping class\n",
    "class EarlyStopping:\n",
    "    def __init__(self, tolerance=5, min_delta=0):\n",
    "\n",
    "        self.tolerance = tolerance\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, train_loss, validation_loss):\n",
    "        if abs(validation_loss - train_loss) < self.min_delta:\n",
    "            self.counter +=1\n",
    "            if self.counter >= self.tolerance:  \n",
    "                self.early_stop = True\n",
    "\n",
    "# Define model, loss function, optimizer and other hyper-parameters\n",
    "import torch.optim as optim\n",
    "dev = torch.device('mps' if mps.is_available() else 'cpu') # GPU support for PyTorch in MacOS\n",
    "# dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # GPU support for PyTorch if CUDA is available\n",
    "\n",
    "\n",
    "model = ConvNeuralNet() # Based on VGG architecture\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "early_stopping = EarlyStopping(tolerance=3, min_delta=0.1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6da4dad",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b779433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm as tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train(model, num_epochs, train_loader, test_loader, criterion, optimizer, early_stopping, dev):\n",
    "    train_log = {'acc': [], 'loss': []}\n",
    "    val_log = {'acc': [], 'loss': []}\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct, train_total = 0.0, 0.0\n",
    "\n",
    "        for _, (images, labels) in enumerate(tqdm(train_loader, position=0, leave=True, ascii=False)):\n",
    "            \n",
    "            images, labels = images.to(dev), labels.to(dev)\n",
    "\n",
    "            optimizer.zero_grad() # Zero out the gradients for initialisation\n",
    "            outputs = model(images) # Compute output for Forward pass\n",
    "            loss = criterion(outputs, labels) # Compute loss\n",
    "            loss.backward() # Perform backpropagation step\n",
    "            optimizer.step() # Update the weights\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_accuracy = train_correct / train_total\n",
    "        train_log['acc'].append(train_accuracy)\n",
    "        train_log['loss'].append(train_loss)\n",
    "        \n",
    "\n",
    "    # Validation Process\n",
    "        with torch.no_grad(): \n",
    "            valid_correct, valid_total = 0.0, 0.0\n",
    "            valid_loss = 0\n",
    "            model.eval()\n",
    "            for _, (images, labels) in enumerate(tqdm(test_loader, position=0, leave=False, ascii=False)):\n",
    "                images, labels = images.to(dev), labels.to(dev)\n",
    "                \n",
    "                outputs = model(images)\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                valid_correct += (predicted == labels).sum().item()\n",
    "                valid_total += labels.size(0)\n",
    "                valid_loss += criterion(outputs, labels).item()\n",
    "            \n",
    "            valid_accuracy = 100*valid_correct/valid_total\n",
    "            valid_loss /= len(test_loader)\n",
    "\n",
    "        # Early Stopping for avoiding overfit\n",
    "        print(f'Epoch {epoch+1}: Train Loss= {train_loss:.3f}, Train Accuracy: {100*train_accuracy:.3f}%, Validation Loss = {valid_loss:.2f}, Validation Accuracy = {valid_accuracy:.2f}%') \n",
    "\n",
    "        # Keeping the metrics\n",
    "        val_log['acc'].append(train_accuracy)\n",
    "        val_log['loss'].append(train_loss)\n",
    "\n",
    "        \n",
    "        # Early stopping\n",
    "        if early_stopping(valid_loss, train_loss):\n",
    "            print(\"We are at epoch:\", epoch)\n",
    "            break\n",
    "\n",
    "    print('Finished training')\n",
    "    return model, train_log, val_log\n",
    "\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 5\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "num_epochs = 30\n",
    "\n",
    "trained_model, train_log, val_log =  train(model, num_epochs, train_loader, test_loader, criterion, optimizer, early_stopping, dev)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a95d87a3",
   "metadata": {},
   "source": [
    "## Training code (K-folds)\n",
    "\n",
    "In this part, we defined the training of the CNN model. Furthermore, we are specifying it for 30 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6deb436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch 1 Training: loss = 0.697\n",
      "Epoch 2 Training: loss = 0.672\n",
      "Epoch 3 Training: loss = 0.648\n",
      "Epoch 4 Training: loss = 0.619\n",
      "Epoch 5 Training: loss = 0.629\n",
      "Epoch 6 Training: loss = 0.573\n",
      "Epoch 7 Training: loss = 0.547\n",
      "Epoch 8 Training: loss = 0.519\n",
      "Epoch 9 Training: loss = 0.484\n",
      "Epoch 10 Training: loss = 0.458\n",
      "Epoch 11 Training: loss = 0.491\n",
      "Epoch 12 Training: loss = 0.413\n",
      "Epoch 13 Training: loss = 0.481\n",
      "Epoch 14 Training: loss = 0.472\n",
      "Epoch 15 Training: loss = 0.402\n",
      "Epoch 16 Training: loss = 0.372\n",
      "Epoch 17 Training: loss = 0.370\n",
      "Epoch 18 Training: loss = 0.366\n",
      "Epoch 19 Training: loss = 0.348\n",
      "Epoch 20 Training: loss = 0.315\n",
      "Epoch 21 Training: loss = 0.368\n",
      "Epoch 22 Training: loss = 0.337\n",
      "Epoch 23 Training: loss = 0.305\n",
      "Epoch 24 Training: loss = 0.293\n",
      "Epoch 25 Training: loss = 0.295\n",
      "Epoch 26 Training: loss = 0.280\n",
      "Epoch 27 Training: loss = 0.291\n",
      "Epoch 28 Training: loss = 0.230\n",
      "Epoch 29 Training: loss = 0.294\n",
      "Epoch 30 Training: loss = 0.284\n",
      "Finished training \n",
      "\n",
      "Accuracy for fold 1 = 94.118%\n",
      "\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch 1 Training: loss = 0.717\n",
      "Epoch 2 Training: loss = 0.671\n",
      "Epoch 3 Training: loss = 0.641\n",
      "Epoch 4 Training: loss = 0.626\n",
      "Epoch 5 Training: loss = 0.597\n",
      "Epoch 6 Training: loss = 0.562\n",
      "Epoch 7 Training: loss = 0.548\n",
      "Epoch 8 Training: loss = 0.524\n",
      "Epoch 9 Training: loss = 0.517\n",
      "Epoch 10 Training: loss = 0.460\n",
      "Epoch 11 Training: loss = 0.423\n",
      "Epoch 12 Training: loss = 0.414\n",
      "Epoch 13 Training: loss = 0.388\n",
      "Epoch 14 Training: loss = 0.359\n",
      "Epoch 15 Training: loss = 0.316\n",
      "Epoch 16 Training: loss = 0.324\n",
      "Epoch 17 Training: loss = 0.330\n",
      "Epoch 18 Training: loss = 0.347\n",
      "Epoch 19 Training: loss = 0.289\n",
      "Epoch 20 Training: loss = 0.284\n",
      "Epoch 21 Training: loss = 0.264\n",
      "Epoch 22 Training: loss = 0.269\n",
      "Epoch 23 Training: loss = 0.294\n",
      "Epoch 24 Training: loss = 0.238\n",
      "Epoch 25 Training: loss = 0.250\n",
      "Epoch 26 Training: loss = 0.276\n",
      "Epoch 27 Training: loss = 0.253\n",
      "Epoch 28 Training: loss = 0.188\n",
      "Epoch 29 Training: loss = 0.294\n",
      "Epoch 30 Training: loss = 0.245\n",
      "Finished training \n",
      "\n",
      "Accuracy for fold 2 = 85.294%\n",
      "\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch 1 Training: loss = 0.691\n",
      "Epoch 2 Training: loss = 0.688\n",
      "Epoch 3 Training: loss = 0.632\n",
      "Epoch 4 Training: loss = 0.601\n",
      "Epoch 5 Training: loss = 0.612\n",
      "Epoch 6 Training: loss = 0.557\n",
      "Epoch 7 Training: loss = 0.558\n",
      "Epoch 8 Training: loss = 0.516\n",
      "Epoch 9 Training: loss = 0.502\n",
      "Epoch 10 Training: loss = 0.478\n",
      "Epoch 11 Training: loss = 0.438\n",
      "Epoch 12 Training: loss = 0.454\n",
      "Epoch 13 Training: loss = 0.393\n",
      "Epoch 14 Training: loss = 0.430\n",
      "Epoch 15 Training: loss = 0.416\n",
      "Epoch 16 Training: loss = 0.319\n",
      "Epoch 17 Training: loss = 0.343\n",
      "Epoch 18 Training: loss = 0.330\n",
      "Epoch 19 Training: loss = 0.303\n",
      "Epoch 20 Training: loss = 0.315\n",
      "Epoch 21 Training: loss = 0.314\n",
      "Epoch 22 Training: loss = 0.296\n",
      "Epoch 23 Training: loss = 0.242\n",
      "Epoch 24 Training: loss = 0.261\n",
      "Epoch 25 Training: loss = 0.277\n",
      "Epoch 26 Training: loss = 0.231\n",
      "Epoch 27 Training: loss = 0.337\n",
      "Epoch 28 Training: loss = 0.268\n",
      "Epoch 29 Training: loss = 0.188\n",
      "Epoch 30 Training: loss = 0.203\n",
      "Finished training \n",
      "\n",
      "Accuracy for fold 3 = 82.353%\n",
      "\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch 1 Training: loss = 0.699\n",
      "Epoch 2 Training: loss = 0.667\n",
      "Epoch 3 Training: loss = 0.617\n",
      "Epoch 4 Training: loss = 0.624\n",
      "Epoch 5 Training: loss = 0.556\n",
      "Epoch 6 Training: loss = 0.523\n",
      "Epoch 7 Training: loss = 0.565\n",
      "Epoch 8 Training: loss = 0.494\n",
      "Epoch 9 Training: loss = 0.476\n",
      "Epoch 10 Training: loss = 0.491\n",
      "Epoch 11 Training: loss = 0.440\n",
      "Epoch 12 Training: loss = 0.392\n",
      "Epoch 13 Training: loss = 0.388\n",
      "Epoch 14 Training: loss = 0.386\n",
      "Epoch 15 Training: loss = 0.384\n",
      "Epoch 16 Training: loss = 0.359\n",
      "Epoch 17 Training: loss = 0.343\n",
      "Epoch 18 Training: loss = 0.286\n",
      "Epoch 19 Training: loss = 0.297\n",
      "Epoch 20 Training: loss = 0.267\n",
      "Epoch 21 Training: loss = 0.253\n",
      "Epoch 22 Training: loss = 0.307\n",
      "Epoch 23 Training: loss = 0.317\n",
      "Epoch 24 Training: loss = 0.291\n",
      "Epoch 25 Training: loss = 0.285\n",
      "Epoch 26 Training: loss = 0.236\n",
      "Epoch 27 Training: loss = 0.195\n",
      "Epoch 28 Training: loss = 0.204\n",
      "Epoch 29 Training: loss = 0.231\n",
      "Epoch 30 Training: loss = 0.199\n",
      "Finished training \n",
      "\n",
      "Accuracy for fold 4 = 91.176%\n",
      "\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Epoch 1 Training: loss = 0.682\n",
      "Epoch 2 Training: loss = 0.675\n",
      "Epoch 3 Training: loss = 0.625\n",
      "Epoch 4 Training: loss = 0.631\n",
      "Epoch 5 Training: loss = 0.609\n",
      "Epoch 6 Training: loss = 0.587\n",
      "Epoch 7 Training: loss = 0.565\n",
      "Epoch 8 Training: loss = 0.519\n",
      "Epoch 9 Training: loss = 0.471\n",
      "Epoch 10 Training: loss = 0.459\n",
      "Epoch 11 Training: loss = 0.434\n",
      "Epoch 12 Training: loss = 0.478\n",
      "Epoch 13 Training: loss = 0.415\n",
      "Epoch 14 Training: loss = 0.378\n",
      "Epoch 15 Training: loss = 0.355\n",
      "Epoch 16 Training: loss = 0.345\n",
      "Epoch 17 Training: loss = 0.366\n",
      "Epoch 18 Training: loss = 0.376\n",
      "Epoch 19 Training: loss = 0.361\n",
      "Epoch 20 Training: loss = 0.298\n",
      "Epoch 21 Training: loss = 0.362\n",
      "Epoch 22 Training: loss = 0.322\n",
      "Epoch 23 Training: loss = 0.258\n",
      "Epoch 24 Training: loss = 0.258\n",
      "Epoch 25 Training: loss = 0.254\n",
      "Epoch 26 Training: loss = 0.297\n",
      "Epoch 27 Training: loss = 0.262\n",
      "Epoch 28 Training: loss = 0.256\n",
      "Epoch 29 Training: loss = 0.265\n",
      "Epoch 30 Training: loss = 0.222\n",
      "Finished training \n",
      "\n",
      "Accuracy for fold 5 = 88.235%\n",
      "\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "----------------------------------------------------\n",
      "Average Accuracy = 88.24%\n",
      "Test accuracy = 91.18%\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm as tqdm\n",
    "from torch.utils.data import SubsetRandomSampler, DataLoader\n",
    "from torch.backends import mps\n",
    "import numpy as np\n",
    "\n",
    "def training_Kfold(model, num_epochs, data_set, kfold, criterion, optimizer, save_model=True, savepath=\"CNN_model.pth\"):\n",
    "    \"\"\"\n",
    "    Training function\n",
    "    -----------------\n",
    "    Input:\n",
    "        model: PyTorch model\n",
    "        num_epochs: Number of maximum epochs\n",
    "        train_loader: DataLoader type dataset for training\n",
    "        test_loader: DataLoader type dataset for validation\n",
    "        criterion: Loss function\n",
    "        optimizer: Optimizer function for the training\n",
    "        early_stopping: EarlyStopping functionality \n",
    "        save_model: If True, then it saves the model parameters\n",
    "    Output:\n",
    "        model: Trained PyTorch model\n",
    "        training_log: Data of the training results for further use\n",
    "    \"\"\"\n",
    "    \n",
    "    def reset_weights(m):\n",
    "        '''\n",
    "        Try resetting model weights to avoid weight leakage.\n",
    "        '''\n",
    "        for layer in m.children():\n",
    "            if hasattr(layer, 'reset_parameters'):\n",
    "                # print(f'Reset trainable parameters of layer = {layer}')\n",
    "                layer.reset_parameters()\n",
    "\n",
    "\n",
    "    torch.manual_seed(42) # Set fixed random number seed for reproducibility\n",
    "    dev = torch.device('mps' if mps.is_available() else 'cpu') # GPU support for PyTorch in MacOS\n",
    "    train_log = {'loss': []}\n",
    "    fold_log = {'acc': []}\n",
    "\n",
    "\n",
    "    for fold, (train_ids, test_ids) in enumerate(kfold.split(data_set)):\n",
    "\n",
    "        print(f'FOLD {fold+1}')\n",
    "        print('--------------------------------')\n",
    "    \n",
    "        # Sample elements randomly from a given list of ids, no replacement.\n",
    "        train_subsampler = SubsetRandomSampler(train_ids)\n",
    "        test_subsampler = SubsetRandomSampler(test_ids)\n",
    "    \n",
    "        # Define data loaders for training and testing data in this fold\n",
    "        train_loader = DataLoader(data_set, batch_size=5, sampler=train_subsampler)\n",
    "        test_loader = DataLoader(data_set, batch_size=5, sampler=test_subsampler)\n",
    "\n",
    "        model.apply(reset_weights)\n",
    "        model.to(dev)\n",
    "        train_loss, train_accuracy = 0.0, 0.0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            current_train_loss = 0.0\n",
    "            # train_correct, train_count = 0.0, 0.0\n",
    "\n",
    "            for _, (images, labels) in enumerate(train_loader):\n",
    "                \n",
    "                images = images.to(dev)\n",
    "                labels = labels.to(dev)\n",
    "\n",
    "                optimizer.zero_grad() # Zero out the gradients for initialisation\n",
    "                outputs = model(images) # Compute output for Forward pass\n",
    "                loss = criterion(outputs, labels) # Compute loss\n",
    "                loss.backward() # Perform backpropagation step\n",
    "                optimizer.step() # Update the weights\n",
    "\n",
    "                current_train_loss += loss.item()\n",
    "                # _, predicted = torch.max(outputs.data, 1)\n",
    "                # train_correct += (predicted == labels).sum().item()\n",
    "                # train_count += labels.size(0) \n",
    "\n",
    "            current_train_loss /= len(train_loader)\n",
    "            # current_train_accuracy = train_correct / train_count\n",
    "            print(f\"Epoch {epoch+1} Training: loss = {current_train_loss:.3f}\")\n",
    "            train_loss += current_train_loss\n",
    "            # train_accuracy += current_train_accuracy\n",
    "\n",
    "        \n",
    "        print('Finished training \\n')\n",
    "        if save_model: torch.save(model.state_dict(), savepath)\n",
    "\n",
    "        # Validation Process\n",
    "        valid_correct, valid_total = 0, 0\n",
    "        with torch.no_grad(): \n",
    "            # valid_loss = 0\n",
    "            for _, (images, labels) in enumerate(test_loader):\n",
    "                images, labels = images.to(dev), labels.to(dev)\n",
    "                outputs = model(images)\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                valid_correct += (predicted == labels).sum().item()\n",
    "                valid_total += labels.size(0)\n",
    "                \n",
    "        # Printing and saving the metrics for later use\n",
    "        print(f'Accuracy for fold {fold+1} = {100*valid_correct / valid_total:.3f}%\\n')\n",
    "        train_log['loss'].append(train_loss/num_epochs)\n",
    "        fold_log['acc'].append(valid_correct/valid_total)\n",
    "\n",
    "    # Print fold results\n",
    "    print(f'K-FOLD CROSS VALIDATION RESULTS FOR {fold+1} FOLDS')\n",
    "    print('----------------------------------------------------')\n",
    "    print(f\"Average Accuracy = {np.mean(fold_log['acc'])*100:.2f}%\")\n",
    "\n",
    "    return model.to(\"cpu\"), train_log, fold_log\n",
    "\n",
    "trained_model, loss_log, test_log = training_Kfold(model, num_epochs=30, data_set=data_set, \n",
    "                                                   kfold=kfold, criterion=criterion, optimizer=optimizer, \n",
    "                                                   save_model=True, savepath=\"CNN_model.pth\")\n",
    "\n",
    "\n",
    "def test(trained_model, test_dataset, batch_size=5):\n",
    "    \"\"\"\n",
    "    Testing the trained model with K-fold\n",
    "    \"\"\"\n",
    "    test_loader = DataLoader(test_dataset, batch_size, shuffle=True)\n",
    "    with torch.no_grad():\n",
    "        test_correct, test_total = 0.0, 0.0\n",
    "        for _, (images, labels) in enumerate(test_loader):\n",
    "            outputs = trained_model(images)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "            test_total += labels.size(0)\n",
    "        \n",
    "        test_acc = test_correct/test_total\n",
    "    print(f\"Test accuracy = {test_acc*100:.2f}%\")\n",
    "\n",
    "test(trained_model, test_dataset, batch_size=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
